{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#111111111222222222233333333334444444444555555555566666666667777777777888888888899999999990000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "import pyspark\n",
    "spark_context = pyspark.SparkContext()\n",
    "spark_session = pyspark.sql.SparkSession(spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+---+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "|    _c0| _c1| _c2|_c3|  _c4|  _c5|  _c6|   _c7|_c8|  _c9|_c10|  _c11| _c12|_c13|\n",
      "+-------+----+----+---+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "|0.00632|18.0|2.31|  0|0.538|6.575| 65.2|  4.09|  1|296.0|15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0|7.07|  0|0.469|6.421| 78.9|4.9671|  2|242.0|17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0|7.07|  0|0.469|7.185| 61.1|4.9671|  2|242.0|17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0|2.18|  0|0.458|6.998| 45.8|6.0622|  3|222.0|18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0|2.18|  0|0.458|7.147| 54.2|6.0622|  3|222.0|18.7| 396.9| 5.33|36.2|\n",
      "|0.02985| 0.0|2.18|  0|0.458| 6.43| 58.7|6.0622|  3|222.0|18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5|7.87|  0|0.524|6.012| 66.6|5.5605|  5|311.0|15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5|7.87|  0|0.524|6.172| 96.1|5.9505|  5|311.0|15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5|7.87|  0|0.524|5.631|100.0|6.0821|  5|311.0|15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5|7.87|  0|0.524|6.004| 85.9|6.5921|  5|311.0|15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5|7.87|  0|0.524|6.377| 94.3|6.3467|  5|311.0|15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5|7.87|  0|0.524|6.009| 82.9|6.2267|  5|311.0|15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5|7.87|  0|0.524|5.889| 39.0|5.4509|  5|311.0|15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0|8.14|  0|0.538|5.949| 61.8|4.7075|  4|307.0|21.0| 396.9| 8.26|20.4|\n",
      "|0.63796| 0.0|8.14|  0|0.538|6.096| 84.5|4.4619|  4|307.0|21.0|380.02|10.26|18.2|\n",
      "|0.62739| 0.0|8.14|  0|0.538|5.834| 56.5|4.4986|  4|307.0|21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0|8.14|  0|0.538|5.935| 29.3|4.4986|  4|307.0|21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0|8.14|  0|0.538| 5.99| 81.7|4.2579|  4|307.0|21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0|8.14|  0|0.538|5.456| 36.6|3.7965|  4|307.0|21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0|8.14|  0|0.538|5.727| 69.5|3.7965|  4|307.0|21.0|390.95|11.28|18.2|\n",
      "+-------+----+----+---+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv file into dataframe\n",
    "df = spark_session.read.csv(\"../nhousing.csv\", header=False, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- crim: double (nullable = true)\n",
      " |-- zn: double (nullable = true)\n",
      " |-- indux: double (nullable = true)\n",
      " |-- chas: integer (nullable = true)\n",
      " |-- nox: double (nullable = true)\n",
      " |-- rm: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- dis: double (nullable = true)\n",
      " |-- rad: integer (nullable = true)\n",
      " |-- tax: double (nullable = true)\n",
      " |-- ptratio: double (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- lstat: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename the columns to be more descriptive\n",
    "df = df.selectExpr(\"_c0 as crim\", \"_c1 as zn\", \"_c2 as indux\", \\\n",
    "                   \"_c3 as chas\", \"_c4 as nox\", \"_c5 as rm\", \\\n",
    "                   \"_c6 as age\", \"_c7 as dis\", \"_c8 as rad\", \\\n",
    "                   \"_c9 as tax\", \"_c10 as ptratio\", \"_c11 as b\", \\\n",
    "                   \"_c12 as lstat\", \"_c13 as price\")\n",
    "df.printSchema()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|price|\n",
      "+--------------------+-----+\n",
      "|[0.00632,18.0,2.3...| 24.0|\n",
      "|[0.02731,0.0,7.07...| 21.6|\n",
      "|[0.02729,0.0,7.07...| 34.7|\n",
      "|[0.03237,0.0,2.18...| 33.4|\n",
      "|[0.06905,0.0,2.18...| 36.2|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform into a dataframe suitable for machine learning\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler( inputCols = \\\n",
    "    ['crim', 'zn', 'indux', 'chas', 'nox', 'rm', 'age', \\\n",
    "     'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], \\\n",
    "    outputCol = 'features' )\n",
    "mldf = vectorAssembler.transform(df)\n",
    "mldf = mldf.select(['features','price'])\n",
    "mldf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test dataframe\n",
    "train_df, test_df = mldf.randomSplit([0.8, 0.2],seed=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=1)\n",
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|price|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|27.642081520013004| 24.5|[0.01501,80.0,2.0...|\n",
      "| 37.38343171546305| 44.0|[0.01538,90.0,3.7...|\n",
      "| 30.88036863886255| 32.9|[0.01778,95.0,1.4...|\n",
      "|24.996936690822892| 28.7|[0.02985,0.0,2.18...|\n",
      "|28.607146504811347| 31.2|[0.03049,55.0,3.7...|\n",
      "|28.657301643210953| 33.4|[0.03237,0.0,2.18...|\n",
      "|21.930980863804976| 20.6|[0.03306,0.0,5.19...|\n",
      "| 19.92105697438567| 19.5|[0.03427,0.0,5.19...|\n",
      "| 28.61431265464769| 24.1|[0.03445,82.5,2.0...|\n",
      "| 41.86804404177727| 48.5|[0.0351,95.0,2.68...|\n",
      "|21.953281009049668| 20.6|[0.04527,0.0,11.9...|\n",
      "|  19.9581230578766| 17.1|[0.05023,35.0,6.0...|\n",
      "|22.224641784694743| 22.2|[0.05083,0.0,5.19...|\n",
      "| 21.92355620842548| 22.5|[0.05188,0.0,4.49...|\n",
      "| 27.65879461624145| 25.0|[0.0536,21.0,5.64...|\n",
      "|27.415326668145696| 27.1|[0.05372,0.0,13.9...|\n",
      "| 35.96042318109285| 50.0|[0.05602,0.0,2.46...|\n",
      "| 27.45995140184931| 26.6|[0.05735,0.0,4.49...|\n",
      "|27.442416035066447| 23.9|[0.06076,0.0,11.9...|\n",
      "| 35.21514246203778| 33.1|[0.06127,40.0,6.4...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.749762\n"
     ]
    }
   ],
   "source": [
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R Squared: 0.694189\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.749762\n",
      "Test R Squared: 0.694189\n"
     ]
    }
   ],
   "source": [
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=50)\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\")\n",
    "\n",
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.681938\n",
      "Test R Squared: 0.605846\n"
     ]
    }
   ],
   "source": [
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=100, regParam=1, elasticNetParam=1 )\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\")\n",
    "\n",
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.735784\n",
      "Test R Squared: 0.655029\n"
     ]
    }
   ],
   "source": [
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=50, regParam=0.2, elasticNetParam=0.85 )\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\")\n",
    "\n",
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.735784\n",
      "Test R Squared: 0.655029\n"
     ]
    }
   ],
   "source": [
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=100, regParam=0.2, elasticNetParam=0.85 )\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\")\n",
    "\n",
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R Squared: 0.724882\n",
      "Test R Squared: 0.691233\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test dataframe\n",
    "train_df, test_df = mldf.randomSplit([0.8, 0.2],seed=20) \n",
    "\n",
    "# Train user linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', \\\n",
    "        labelCol='price', maxIter=100, regParam=0.2, elasticNetParam=0.85 )\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Do some predictions on the hold-out, test set\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\")\n",
    "\n",
    "print(\"Training R Squared: %f\" % lr_model.summary.r2)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator( predictionCol=\"prediction\", \\\n",
    "    labelCol=\"price\", metricName=\"r2\" )\n",
    "print(\"Test R Squared: %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

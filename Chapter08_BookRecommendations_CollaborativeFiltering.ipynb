{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#111111111222222222233333333334444444444555555555566666666667777777777888888888899999999990000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "import pyspark\n",
    "spark_context = pyspark.SparkContext()\n",
    "spark_session = pyspark.sql.SparkSession(spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|book_id|user_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    314|     5|\n",
      "|      1|    439|     3|\n",
      "|      1|    588|     5|\n",
      "|      1|   1169|     4|\n",
      "|      1|   1185|     4|\n",
      "|      1|   2077|     4|\n",
      "|      1|   2487|     4|\n",
      "|      1|   2900|     5|\n",
      "|      1|   3662|     4|\n",
      "|      1|   3922|     5|\n",
      "|      1|   5379|     5|\n",
      "|      1|   5461|     3|\n",
      "|      1|   5885|     5|\n",
      "|      1|   6630|     5|\n",
      "|      1|   7563|     3|\n",
      "|      1|   9246|     1|\n",
      "|      1|  10140|     4|\n",
      "|      1|  10146|     5|\n",
      "|      1|  10246|     4|\n",
      "|      1|  10335|     4|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv file into dataframe\n",
    "df = spark_session.read.csv(\"ratings.csv\", header=True,\\\n",
    "                    sep=\",\", inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema to get the column names\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test dataframe\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2],seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train via collaborative filtering using ALS modeling\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "als = ALS(maxIter=1, \\\n",
    "          userCol=\"user_id\", itemCol=\"book_id\", \\\n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+------------+\n",
      "|book_id|user_id|rating|  prediction|\n",
      "+-------+-------+------+------------+\n",
      "|    148|  35982|     3| -0.31140882|\n",
      "|    148|    588|     4|  0.92572826|\n",
      "|    148|   6630|     3|   0.4292102|\n",
      "|    148|  32055|     3|0.0058147907|\n",
      "|    148|   5461|     4|   3.0499282|\n",
      "|    148|  29703|     4| 0.041774243|\n",
      "|    148|   8440|     3|    2.459359|\n",
      "|    148|  29031|     3|   0.6628299|\n",
      "|    148|   8510|     3|   2.2513313|\n",
      "|    148|   8579|     3|    2.166421|\n",
      "|    148|  51166|     4|   2.3413692|\n",
      "|    148|  25840|     3|  0.36833537|\n",
      "|    148|  27027|     5|   2.1993814|\n",
      "|    148|  19191|     4|   2.2397602|\n",
      "|    148|   9246|     3|   0.7226782|\n",
      "|    148|  30681|     2| 0.055203795|\n",
      "|    148|   3005|     5|   4.8201756|\n",
      "|    148|  11945|     4|   1.7858065|\n",
      "|    148|  23612|     4|  0.64917624|\n",
      "|    148|  37834|     3|   1.6805291|\n",
      "+-------+-------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings on the test set\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 3.973465155014813\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\\\n",
    "        predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train via collaborative filtering using ALS modeling\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "als = ALS(maxIter=2, \\\n",
    "          userCol=\"user_id\", itemCol=\"book_id\", \\\n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|book_id|user_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|    148|  35982|     3|  2.446461|\n",
      "|    148|    588|     4| 2.9079287|\n",
      "|    148|   6630|     3| 3.0344589|\n",
      "|    148|  32055|     3| 2.7123644|\n",
      "|    148|   5461|     4| 3.7742112|\n",
      "|    148|  29703|     4|  3.292892|\n",
      "|    148|   8440|     3| 2.8392575|\n",
      "|    148|  29031|     3| 2.9192214|\n",
      "|    148|   8510|     3|  2.819971|\n",
      "|    148|   8579|     3| 2.8995452|\n",
      "|    148|  51166|     4| 3.6051712|\n",
      "|    148|  25840|     3|  3.071086|\n",
      "|    148|  27027|     5| 2.5246549|\n",
      "|    148|  19191|     4|  3.070326|\n",
      "|    148|   9246|     3| 2.7046995|\n",
      "|    148|  30681|     2|  2.723502|\n",
      "|    148|   3005|     5| 3.4284286|\n",
      "|    148|  11945|     4| 3.3822477|\n",
      "|    148|  23612|     4| 3.1713557|\n",
      "|    148|  37834|     3| 3.5440595|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings on the test set\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 2.305931931499659\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\\\n",
    "        predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    148|[[3033, 7.394059]...|\n",
      "|    463|[[9529, 8.791248]...|\n",
      "|    471|[[3491, 4.8327417...|\n",
      "|    496|[[9529, 8.452917]...|\n",
      "|    833|[[5354, 6.7187777...|\n",
      "|   1088|[[7728, 5.5623875...|\n",
      "|   1238|[[1618, 3.9393585...|\n",
      "|   1342|[[3172, 7.2099924...|\n",
      "|   1580|[[5205, 7.797331]...|\n",
      "|   1591|[[9769, 5.4881206...|\n",
      "|   1645|[[9096, 5.158281]...|\n",
      "|   1829|[[2586, 9.483122]...|\n",
      "|   1959|[[9345, 2.1017418...|\n",
      "|   2122|[[7281, 5.4459467...|\n",
      "|   2142|[[9096, 8.911084]...|\n",
      "|   2366|[[1495, 8.855446]...|\n",
      "|   2659|[[8859, 6.805735]...|\n",
      "|   2866|[[4291, 9.066534]...|\n",
      "|   3175|[[9479, 7.6684184...|\n",
      "|   3749|[[3604, 7.6168547...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating=7.4, The Right Stuff\n",
      "rating=6.8, The Dispossessed\n",
      "rating=6.8, You're Never Weird on the Internet (Almost)\n",
      "rating=6.8, The Intelligent Investor (Collins Business Essentials)\n",
      "rating=6.8, Born to Run: A Hidden Tribe, Superathletes, and the Greatest Race the World Has Never Seen\n",
      "rating=6.7, Watchmen\n",
      "rating=6.7, V for Vendetta\n",
      "rating=6.6, One True Thing\n",
      "rating=6.6, Strength in What Remains: A Journey of Remembrance and Forgiveness\n",
      "rating=6.6, The Hobbit: Graphic Novel\n"
     ]
    }
   ],
   "source": [
    "# Load the books CSV\n",
    "books_df = spark_session.read.csv(\"books.csv\", header=True,\\\n",
    "                    sep=\",\", inferSchema=True)\n",
    "\n",
    "# Grab the first user's recommendations, and get the book names\n",
    "recs = userRecs.first().recommendations\n",
    "\n",
    "# List the details of the top 10 recommendations for this user\n",
    "from pyspark.sql.functions import col\n",
    "for pair in recs:\n",
    "    book_id = pair.book_id\n",
    "    rating = pair.rating\n",
    "    title = books_df[ books_df.id == book_id ].select( col(\"title\"))\n",
    "    print( \"rating=%1.1f, %s\" % ( rating, title.first().title ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|book_id|user_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|    148|  35982|     3| 2.9441757|\n",
      "|    148|    588|     4| 3.2421308|\n",
      "|    148|   6630|     3|   3.47851|\n",
      "|    148|  32055|     3| 3.1640284|\n",
      "|    148|   5461|     4| 3.7821462|\n",
      "|    148|  29703|     4|  3.990831|\n",
      "|    148|   8440|     3| 3.0593615|\n",
      "|    148|  29031|     3| 3.5942922|\n",
      "|    148|   8510|     3|  3.276093|\n",
      "|    148|   8579|     3| 3.0420232|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Root-mean-square error = 1.0619829028186363\n"
     ]
    }
   ],
   "source": [
    "# Train via collaborative filtering using ALS modeling\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "als = ALS(maxIter=4, \\\n",
    "          userCol=\"user_id\", itemCol=\"book_id\", \\\n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(df_train)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.show(10)\n",
    "\n",
    "# Evaluate the predictions using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\\\n",
    "        predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    148|[[2865, 4.6972713...|\n",
      "+-------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "rating=4.7, The Gashlycrumb Tinies (The Vinegar Works, #1)\n",
      "rating=4.7, The Complete Anne of Green Gables Boxed Set (Anne of Green Gables, #1-8)\n",
      "rating=4.7, The Power of One (The Power of One, #1)\n",
      "rating=4.7, Harry Potter Collection (Harry Potter, #1-6)\n",
      "rating=4.6, Lamb: The Gospel According to Biff, Christ's Childhood Pal\n",
      "rating=4.6, The Complete Calvin and Hobbes\n",
      "rating=4.6, Between the World and Me\n",
      "rating=4.5, Words of Radiance (The Stormlight Archive, #2)\n",
      "rating=4.5, The Warmth of Other Suns: The Epic Story of America's Great Migration\n",
      "rating=4.5, The Night Before Christmas\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.show(1)\n",
    "\n",
    "# Grab the first user's recommendations, and get the book names\n",
    "recs = userRecs.first().recommendations\n",
    "\n",
    "# List the details of the top 10 recommendations for this user\n",
    "from pyspark.sql.functions import col\n",
    "for pair in recs:\n",
    "    title = books_df[ books_df.id == pair.book_id ].select( col(\"title\"))\n",
    "    print( \"rating=%1.1f, %s\" % ( pair.rating, title.first().title ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
